{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import gzip\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np \n",
    "\n",
    "import idx2numpy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_dataset(path):\n",
    "    \n",
    "    f = gzip.open(path, 'rb')\n",
    "    data = torch.from_numpy(idx2numpy.convert_from_file(f))\n",
    "    f.close()\n",
    "    \n",
    "    return(data)\n",
    "\n",
    "\n",
    "def load_all_datasets(train_imgs, train_labs, test_imgs, test_labs, batch_size):\n",
    "    \n",
    "    \n",
    "    train_images = load_one_dataset(train_imgs).type(torch.float32)\n",
    "    train_labels = load_one_dataset(train_labs).type(torch.long)\n",
    "    train = list(zip(train_images, train_labels))\n",
    "    \n",
    "    test_images = load_one_dataset(test_imgs).type(torch.float32)\n",
    "    test_labels = load_one_dataset(test_labs).type(torch.long)\n",
    "    test = list(zip(test_images, test_labels))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=2, lr=0.001, momentum=0.9, batch_size=512):\n",
    "    \n",
    "    \n",
    "    # Set paths to datasets\n",
    "    paths = {\n",
    "        \n",
    "        'train_imgs': 'train-images-idx3-ubyte.gz',\n",
    "        'train_labs': 'train-labels-idx1-ubyte.gz',\n",
    "        'test_imgs': 't10k-images-idx3-ubyte.gz',\n",
    "        'test_labs': 't10k-labels-idx1-ubyte.gz'\n",
    "    }\n",
    "    \n",
    "    # Load datasets\n",
    "    train_loader, test_loader = load_all_datasets(**paths, batch_size = 256)\n",
    "    \n",
    "    # Set parameters\n",
    "    net = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    # Loop over the dataset multiple times\n",
    "    for epoch in range(epochs):  \n",
    "        \n",
    "        # Initialize running loss\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterate through data now\n",
    "        for i, data in enumerate(train_loader):\n",
    "            \n",
    "            # Get the inputs: data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            \n",
    "            # Optimize\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        # Print every 100 mini-batches\n",
    "        print(\"The loss on epoch {} is {}...\".format(epoch, running_loss))\n",
    "    \n",
    "    # Print message\n",
    "    print('Done training...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-b7613e5401b2>:4: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  data = torch.from_numpy(idx2numpy.convert_from_file(f))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss on epoch 0 is 797.6245762109756...\n",
      "The loss on epoch 1 is 472.9224491119385...\n",
      "The loss on epoch 2 is 455.8873064517975...\n",
      "The loss on epoch 3 is 433.68939542770386...\n",
      "The loss on epoch 4 is 426.67657220363617...\n",
      "The loss on epoch 5 is 423.5025362968445...\n",
      "The loss on epoch 6 is 382.8136829137802...\n",
      "The loss on epoch 7 is 341.8955651521683...\n",
      "The loss on epoch 8 is 336.7372764348984...\n",
      "The loss on epoch 9 is 333.3080538511276...\n",
      "The loss on epoch 10 is 331.7287828922272...\n",
      "The loss on epoch 11 is 330.772274851799...\n",
      "The loss on epoch 12 is 328.16447150707245...\n",
      "The loss on epoch 13 is 326.97206819057465...\n",
      "The loss on epoch 14 is 326.06990802288055...\n",
      "The loss on epoch 15 is 324.09075820446014...\n",
      "The loss on epoch 16 is 324.1867686510086...\n",
      "The loss on epoch 17 is 322.5455080270767...\n",
      "The loss on epoch 18 is 322.8292189836502...\n",
      "The loss on epoch 19 is 321.6163798570633...\n",
      "The loss on epoch 20 is 321.2179615497589...\n",
      "The loss on epoch 21 is 319.9476933479309...\n",
      "The loss on epoch 22 is 319.5597575902939...\n",
      "The loss on epoch 23 is 319.2505202293396...\n",
      "The loss on epoch 24 is 318.2349637746811...\n",
      "The loss on epoch 25 is 317.7195291519165...\n",
      "The loss on epoch 26 is 318.0368469953537...\n",
      "The loss on epoch 27 is 317.4345791339874...\n",
      "The loss on epoch 28 is 316.24621415138245...\n",
      "The loss on epoch 29 is 316.1423680782318...\n",
      "The loss on epoch 30 is 315.4215556383133...\n",
      "The loss on epoch 31 is 314.75013864040375...\n",
      "The loss on epoch 32 is 315.51619589328766...\n",
      "The loss on epoch 33 is 314.22417080402374...\n",
      "The loss on epoch 34 is 314.0988224744797...\n",
      "The loss on epoch 35 is 313.8537038564682...\n",
      "The loss on epoch 36 is 313.19943821430206...\n",
      "The loss on epoch 37 is 312.9325181245804...\n",
      "The loss on epoch 38 is 312.7191354036331...\n",
      "The loss on epoch 39 is 312.59965908527374...\n",
      "The loss on epoch 40 is 301.44430381059647...\n",
      "The loss on epoch 41 is 273.6013312935829...\n",
      "The loss on epoch 42 is 270.3505457639694...\n",
      "The loss on epoch 43 is 269.04009890556335...\n",
      "The loss on epoch 44 is 267.8790667653084...\n",
      "The loss on epoch 45 is 267.69952976703644...\n",
      "The loss on epoch 46 is 266.5899761915207...\n",
      "The loss on epoch 47 is 265.51294672489166...\n",
      "The loss on epoch 48 is 264.93889528512955...\n",
      "The loss on epoch 49 is 264.52771347761154...\n",
      "The loss on epoch 50 is 263.9738621711731...\n"
     ]
    }
   ],
   "source": [
    "train(epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
