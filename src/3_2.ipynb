{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "1_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WDdC5E0llYu",
        "outputId": "d8d122c6-386b-4982-d536-84c2ea14a17b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XQHea_TnP4S",
        "outputId": "3ac433cd-a8fb-4a2e-a548-59a7263c7531"
      },
      "source": [
        "# Install idx2numpy package for extracting data\n",
        "!pip install idx2numpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting idx2numpy\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/6b/80628f6cc2f44d80b27f1ef7b57b257ed4c73766113b77d13ad110c091b4/idx2numpy-1.2.3.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from idx2numpy) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from idx2numpy) (1.15.0)\n",
            "Building wheels for collected packages: idx2numpy\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-cp36-none-any.whl size=7905 sha256=86e2652dea9daf9fcce864e80d96c173414445d4c031494038626702ec92c2d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c1/da/284ce80a748fab898b8d1fa95468a386e7cf3b81da18511f9d\n",
            "Successfully built idx2numpy\n",
            "Installing collected packages: idx2numpy\n",
            "Successfully installed idx2numpy-1.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9CsmgA1jCg4"
      },
      "source": [
        "# Import packages\n",
        "import os\n",
        "import json\n",
        "import gzip\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "import idx2numpy\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmfcKJJCjCg5"
      },
      "source": [
        "def load_one_dataset(path):\n",
        "    '''\n",
        "    Convenience function to load a single dataset\n",
        "    '''\n",
        "    f = gzip.open(path, 'rb')\n",
        "    data = torch.from_numpy(idx2numpy.convert_from_file(f))\n",
        "    f.close()\n",
        "    \n",
        "    return(data)\n",
        "\n",
        "\n",
        "def load_all_datasets(train_imgs, train_labs, test_imgs, test_labs, batch_size):\n",
        "    '''\n",
        "    Load training as well as test images here\n",
        "    '''\n",
        "    train_images = load_one_dataset(train_imgs).type(torch.float32)\n",
        "    train_labels = load_one_dataset(train_labs).type(torch.long)\n",
        "    train = list(zip(train_images, train_labels))\n",
        "\n",
        "    test_images = load_one_dataset(test_imgs).type(torch.float32)\n",
        "    test_labels = load_one_dataset(test_labs).type(torch.long)\n",
        "    test = list(zip(test_images, test_labels))\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    \n",
        "    return(train_loader, test_loader)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP1ydts51HX2",
        "outputId": "44d4e9bc-2ea8-4b53-bbd2-6f8f15e3211d"
      },
      "source": [
        "# Just for testing out noise function\n",
        "data_dir = '/content/drive/MyDrive/data'\n",
        "    \n",
        "paths = {\n",
        "      'train_imgs': os.path.join(data_dir, 'train-images-idx3-ubyte.gz'),\n",
        "      'train_labs': os.path.join(data_dir, 'train-labels-idx1-ubyte.gz'),\n",
        "      'test_imgs': os.path.join(data_dir,'t10k-images-idx3-ubyte.gz'),\n",
        "      'test_labs': os.path.join(data_dir,'t10k-labels-idx1-ubyte.gz')\n",
        "}\n",
        "\n",
        "# Load datasets\n",
        "train_loader, test_loader = load_all_datasets(**paths, batch_size = 32)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY9lnBvi8W8U"
      },
      "source": [
        "def add_noise(img, i, j, h, w, v):\n",
        "  '''\n",
        "  Randomly remove 1 or 2 quadrants\n",
        "  from the input image.\n",
        "  '''\n",
        "  # Store the quadrant definitions: move this into training loop later\n",
        "  quadrants = {\n",
        "      \n",
        "      1: [0, 0, 14, 14, 0], \n",
        "      2: [0, 14, 14, 14, 0],\n",
        "      3: [14, 0, 14, 14, 0],\n",
        "      4: [14, 14, 14, 14, 0],\n",
        "  }\n",
        "\n",
        "  # Get the number of quadrants to erase\n",
        "  n_quads_to_erase = np.random.choice([1, 2])\n",
        "\n",
        "  # Get which quadrants to erase\n",
        "  quads_to_erase = np.random.choice([1, 2, 3, 4], size = n_quads_to_erase)\n",
        "  \n",
        "  # Create a copy of the image\n",
        "  noisy_img = img.clone()\n",
        "\n",
        "  # Now erase the quadrants\n",
        "  for quad in quads_to_erase:\n",
        "    noisy_img = torchvision.transforms.functional.erase(noisy_img, *quadrants[quad])\n",
        "  \n",
        "  # Return statement\n",
        "  return(noisy_img)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka-JOwvYQfIS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}